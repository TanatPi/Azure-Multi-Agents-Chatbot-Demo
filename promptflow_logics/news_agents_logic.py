import asyncio
from semantic_kernel.contents.chat_message_content import ChatMessageContent
from semantic_kernel.contents.utils.author_role import AuthorRole
import ast
import math
from datetime import datetime
today_str = datetime.now().strftime("%B %d, %Y")  # e.g., "July 24, 2025"
#### === Helper functions ===
# === Helper to count token ===
import tiktoken

tokenizer_4o = tiktoken.encoding_for_model("gpt-4o-mini") 
tokenizer_4_1 = tiktoken.get_encoding("o200k_base") # gpt-4.1

def count_tokens(text: str, tokenizer) -> int:
    return len(tokenizer.encode(text))

# === Helper to call one sub-agent ===
async def run_mmrag_agent(agents, search, user_query, search_keywords, filter=None, top_k=10):
    context_text, context_table= await asyncio.gather(
        search.search_text_content(search_keywords, filter=filter, top_k=top_k),
        search.search_table_content(search_keywords, filter=filter, top_k=5),
    )

    user_prompt = f"""Use the following JSON context to answer the question:

        Context text data:
        {context_text}

        Context table data:
        {context_table}

        Question: {user_query}
        """

    input_tokens = count_tokens(user_prompt,tokenizer_4o)

    user_message = ChatMessageContent(role=AuthorRole.USER, content=user_prompt)

    response_text = ""
    async for response in agents.invoke(messages=[user_message]):
        response_text = str(response)

    output_tokens = count_tokens(response_text,tokenizer_4o)

    return response_text, input_tokens, output_tokens

# === Final Agent Flows ===
async def get_news_agent_response(user_query: str, user_thread, main_thread, news_router_agent, orchestrator_agent, pdf_rag_agent, keyword_extractor_agent, pdf_search, language, status, container):
    # === 0. Run sub-router ===
    if status:
        status["router"].markdown("ðŸ”€ Selecting appropriate documents...")

    router_prompt_with_date = f"Today is {today_str}.\n{user_query}"
    router_user_message = ChatMessageContent(role=AuthorRole.USER, content=router_prompt_with_date)
    async for route in news_router_agent.invoke(messages=[router_user_message]):
        route_str = str(route).strip()
        user_thread = route.thread

    # === Token count for router input/output ===
    input_tokens_router = count_tokens(user_query, tokenizer_4_1)
    output_tokens_router = count_tokens(route_str, tokenizer_4_1)

    # === Parse router output (expecting a dict with scores) ===
    try:
        route_scores = ast.literal_eval(route_str)
        assert isinstance(route_scores, dict)
        valid_routes = {"MONTHLYSTANDPOINT", "KCMA", "KTM"}
        route_scores = {k: v for k, v in route_scores.items() if k in valid_routes and isinstance(v, (int, float))}
    except Exception:
        route_scores = {"MONTHLYSTANDPOINT": 10, "KCMA": 0, "KTM": 0}  # fallback

    # === 1. Run Keyword Extractor ===
    if status:
        status["keyword"].markdown("ðŸ” Extracting keywords...")
        status["router"].empty()

    keyword_agent_user_prompt = f"Extract keywords from this query: {user_query}"
    keyword_agent_message = ChatMessageContent(role=AuthorRole.USER, content=keyword_agent_user_prompt)
    keyword_input_tokens = count_tokens(keyword_agent_user_prompt, tokenizer_4_1)

    search_keywords = user_query
    async for response in keyword_extractor_agent.invoke(messages=[keyword_agent_message], thread=user_thread):
        search_keywords = str(response)

    keyword_output_tokens = count_tokens(search_keywords, tokenizer_4_1)

    # === 2. Run RAG agents with score-scaled top_k ===
    if status:
        status["rag"].markdown("ðŸ“š Running RAG agents...")
        status["keyword"].empty()


    # Default base top_k per route
    default_top_k = {
        "MONTHLYSTANDPOINT": 20,
        "KTM": 15,
        "KCMA": 35,
    }

    # Apply nonlinear scaling + bias to scores
    def biased_score(route, score):
        if route == "MONTHLYSTANDPOINT":
            # Square root boost: more weight even at mid scores
            return min(math.sqrt(score) * math.sqrt(10), 10) # sqrt(score) * sqrt(10), bounded to 10
        elif route == "KTM":
            # Squared penalty: suppress low scores
            return min((score ** 2) / 10, 10)
        elif route == "KCMA":
            # Linear but bounded to max of 10
            return min(score, 10)
        else:
            return score

    # Adjusted top_k with score biasing
    adjusted_top_k = {
        route: max(1, int(default_top_k[route] * (biased_score(route, score) / 10)))
        for route, score in route_scores.items() if score > 0
    }

    route_filters = {
        "MONTHLYSTANDPOINT": "key_prefix eq 'monthlystandpoint'",
        "KTM": "key_prefix eq 'ktm'",
        "KCMA": "key_prefix eq 'kcma'",
    }

    rag_tasks = []
    active_responses = {}
    rag_prompt_tokens = 0
    rag_completion_tokens = 0

    for route, top_k in adjusted_top_k.items():
        filter_str = route_filters[route]
        task = run_mmrag_agent(pdf_rag_agent, pdf_search, user_query, search_keywords, filter=filter_str, top_k=top_k)
        rag_tasks.append((route, task))

    results = await asyncio.gather(*(task for _, task in rag_tasks))

    for (route, _), (response, prompt_toks, completion_toks) in zip(rag_tasks, results):
        active_responses[route] = response
        rag_prompt_tokens += prompt_toks
        rag_completion_tokens += completion_toks

    # === 3. Run Orchestrator ===
    if status:
        status["orchestrator"].markdown("ðŸ§  Synthesizing final RAG response...")
        status["rag"].empty()

    orchestrator_sections = []

    if "MONTHLYSTANDPOINT" in active_responses:
        orchestrator_sections.append(f"""
        Information from Monthly Standpoint (monthlystandpoint) document (covering news in this month):
        {active_responses["MONTHLYSTANDPOINT"]}
        """)

    if "KTM" in active_responses:
        orchestrator_sections.append(f"""
        Information from Know the Markets (KTM) document (covering news in this quarter):
        {active_responses["KTM"]}
        """)

    if "KCMA" in active_responses:
        orchestrator_sections.append(f"""
        Information from KAsset Capital Market Assumptions (KCMA) document (published at the start of the year, covering assumptions for the whole year):
        {active_responses["KCMA"]}
        """)

    orchestrator_prompt = f"""
        Today is {today_str}.

        The information given to you are:
        {''.join(orchestrator_sections)}

        If the user's question "{user_query}" mentions specific documents, ignore what is not stated.
        Otherwise, consider all included documents, but prioritize KCMA and Monthly Standpoint over KTM in terms of correctness.
        Cross-check the facts and use those to answer the original question:
        {user_query}

        Please write your final response in a clear {language}, structured way. Make sure no important point is missed.
        """

    orchestrator_message = ChatMessageContent(role=AuthorRole.USER, content=orchestrator_prompt)
    input_tokens_orchestrator = count_tokens(orchestrator_prompt, tokenizer_4_1)

    final_response = ""
    container.markdown(final_response)
    async for orchestration in orchestrator_agent.invoke_stream(messages=[orchestrator_message]):
        final_response += str(orchestration)
        container.markdown(final_response)
        main_thread = orchestration.thread
        has_streamed = True

    output_tokens_orchestrator = count_tokens(final_response, tokenizer_4_1)

    return (
        final_response,
        main_thread,
        input_tokens_router,
        output_tokens_router,
        rag_prompt_tokens,
        rag_completion_tokens,
        input_tokens_orchestrator,
        output_tokens_orchestrator,
        keyword_input_tokens,
        keyword_output_tokens,
        has_streamed
    )
